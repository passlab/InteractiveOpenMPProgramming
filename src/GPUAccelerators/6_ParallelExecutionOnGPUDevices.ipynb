{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b6ab5e9-4f99-42b7-bbdf-7a5b98634513",
   "metadata": {},
   "source": [
    "# Parallel Execution on GPU Devices\n",
    "\n",
    "OpenMP provides directives for parallel execution on GPU devices, allowing programmers to efficiently distribute work across multiple threads and teams. The `teams` and `distribute` directives are key constructs for achieving parallel execution on GPUs. In this section, we will explore the `teams` directive for SPMD (Single Program, Multiple Data) parallelism, the `distribute` directive for work sharing, and how to combine these directives for optimal performance.\n",
    "\n",
    "## teams directive for SPMD parallelism\n",
    "\n",
    "The `teams` directive is used to create a league of thread teams, where each team executes the structured block associated with the directive. This allows for SPMD parallelism, where each team executes the same code but operates on different data.\n",
    "\n",
    "The syntax of the `teams` directive is as follows:\n",
    "\n",
    "```c\n",
    "#pragma omp teams [clause[[,] clause]...]\n",
    "structured-block\n",
    "```\n",
    "\n",
    "The `teams` directive supports clauses such as `num_teams` and `thread_limit` to control the number of teams and the maximum number of threads per team, respectively.\n",
    "\n",
    "Example:\n",
    "```c\n",
    "#pragma omp target teams map(to: a[0:n]) map(from: b[0:n])\n",
    "{\n",
    "  #pragma omp parallel for\n",
    "  for (int i = 0; i < n; i++) {\n",
    "    b[i] = a[i] * 2;\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "In this example, the `teams` directive creates a league of thread teams, and each team executes the parallel loop inside the structured block. The `parallel` directive is used to distribute the loop iterations among the threads within each team.\n",
    "\n",
    "## distribute directive for work sharing\n",
    "\n",
    "The `distribute` directive is used to distribute loop iterations across the master threads of the teams created by the `teams` directive. It provides a way to share work among the teams and achieve parallelism at the team level.\n",
    "\n",
    "The syntax of the `distribute` directive is as follows:\n",
    "\n",
    "```c\n",
    "#pragma omp distribute [clause[[,] clause]...]\n",
    "for-loops\n",
    "```\n",
    "\n",
    "The `distribute` directive supports clauses such as `private`, `firstprivate`, `lastprivate`, and `collapse` to control data sharing and loop collapsing.\n",
    "\n",
    "Example:\n",
    "```c\n",
    "#pragma omp target teams distribute map(to: a[0:n]) map(from: b[0:n])\n",
    "for (int i = 0; i < n; i++) {\n",
    "  b[i] = a[i] * 2;\n",
    "}\n",
    "```\n",
    "\n",
    "In this example, the `distribute` directive distributes the loop iterations across the master threads of the teams. Each team operates on a different portion of the input and output arrays.\n",
    "\n",
    "## Combining teams and distribute directives\n",
    "\n",
    "The `teams` and `distribute` directives can be combined to achieve multi-level parallelism on GPU devices. The `teams` directive creates a league of thread teams, and the `distribute` directive distributes the work among the teams. Additionally, the `parallel` directive can be used within each team to further parallelize the work among the threads within a team.\n",
    "\n",
    "Example:\n",
    "```c\n",
    "#pragma omp target teams distribute map(to: a[0:n]) map(from: b[0:n])\n",
    "for (int i = 0; i < n; i++) {\n",
    "  #pragma omp parallel for\n",
    "  for (int j = 0; j < m; j++) {\n",
    "    b[i] += a[i * m + j];\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "In this example, the `teams` and `distribute` directives are combined to distribute the outer loop iterations across the teams. Within each team, the `parallel` directive is used to parallelize the inner loop iterations among the threads.\n",
    "\n",
    "## Nested parallelism with teams and parallel directives\n",
    "\n",
    "OpenMP supports nested parallelism, where parallel regions can be nested within each other. The `teams` directive can be combined with the `parallel` directive to achieve nested parallelism on GPU devices.\n",
    "\n",
    "Example:\n",
    "```c\n",
    "#pragma omp target teams map(to: a[0:n][0:m]) map(from: b[0:n])\n",
    "{\n",
    "  #pragma omp distribute\n",
    "  for (int i = 0; i < n; i++) {\n",
    "    #pragma omp parallel for reduction(+:b[i])\n",
    "    for (int j = 0; j < m; j++) {\n",
    "      b[i] += a[i][j];\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "In this example, the `teams` directive creates a league of thread teams, and the `distribute` directive distributes the outer loop iterations across the teams. Within each team, the `parallel` directive is used to parallelize the inner loop iterations among the threads, and a reduction is performed to compute the sum of elements in each row of the input array.\n",
    "\n",
    "By using the `teams` and `distribute` directives, along with the `parallel` directive for nested parallelism, programmers can effectively parallelize their code and utilize the full potential of GPU devices.\n",
    "\n",
    "In the next section, we will discuss techniques for tuning the performance of GPU-offloaded code, including choosing the optimal number of teams and threads, optimizing data transfers and memory usage, and leveraging device-specific features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e9060e-071a-444e-bf84-cfe9007ab263",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
