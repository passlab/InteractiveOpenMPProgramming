{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60c352ab",
   "metadata": {},
   "source": [
    "# Creating SPMD parallelism using OpenMP **parallel** and **teams** directive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1c80a7",
   "metadata": {},
   "source": [
    "From this part, we begin to introduce how to use OpenMP directives to write programs. We first introduce the most basic and most commonly used **parallel** directive and **teams** directive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6183b8",
   "metadata": {},
   "source": [
    "## Semantics and Syntax\n",
    "\n",
    "### **parallel** Directive\n",
    "The **parallel** directive is used to mark a parallel region. When a thread encounters a parallel region, a group of threads is created to execute the parallel region.\n",
    "The original thread that executed the serial part will be the primary thread of the new team. All threads in the team execute parallel regions together. After a team is created, the number of threads in the team remains constant for the duration of that parallel region.\n",
    "\n",
    "> Primary thread is also known as the master thread\n",
    "\n",
    "When a thread team is created, the primary thread will implicitly create as many tasks as the number of threads, each task is assigned and bounded to one thread.\n",
    "When threads are all occupied, implicit tasks that have not been allocated will be suspended waiting for idle threads.\n",
    "\n",
    "The following example from Chapter 1 shows how to use the parallel directive in C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f487b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "//%compiler: clang\n",
    "//%cflags: -fopenmp\n",
    "\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <omp.h>\n",
    "\n",
    "int main(int argc, char *argv[]){\n",
    "    #pragma omp parallel\n",
    "    printf(\"%s\\n\", \"Hello World\");\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9634202",
   "metadata": {},
   "source": [
    "This example prints *Hello World* 8 times, which means 8 threads are created by defualt. The default number of threads is determined by the computer hardware, 8 threads are created on the author's computer. \n",
    "The following example shows how to use the num_threads clause in the parallel directive to specify the number of threads to create."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06a9151e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World\n",
      "Hello World\n",
      "Hello World\n",
      "Hello World\n"
     ]
    }
   ],
   "source": [
    "//%compiler: clang\n",
    "//%cflags: -fopenmp\n",
    "\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <omp.h>\n",
    "\n",
    "int main(int argc, char *argv[]){\n",
    "    #pragma omp parallel num_threads(4)\n",
    "    printf(\"%s\\n\", \"Hello World\");\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63291c66",
   "metadata": {},
   "source": [
    "In this example, we use the **num_threads** clause to specify the use of 4 threads to execute the parallel region. When the master thread encounters OpenMP constructs, three threads are created, and together with these three threads, a thread group of 4 is formed. \n",
    "*Hello World* is printed four times, once per thread.\n",
    "\n",
    "Through the above examples, it is not difficult to find that the syntax of parallel directive in C is:\n",
    "\n",
    "```\n",
    "#pragma omp parallel [clause[ [,] clause] ... ] new-line\n",
    "    structured-block\n",
    "```\n",
    "\n",
    "And the syntax of **num_threads** clause isï¼š\n",
    "\n",
    "```\n",
    "num_threads(integer-expression)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4060c3",
   "metadata": {},
   "source": [
    "The next two examples show how to use **paralle** diretcive in Fortran, and they have exactly same meaning as the two examples in C above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f220ae73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Hello World\n",
      " Hello World\n",
      " Hello World\n",
      " Hello World\n",
      " Hello World\n",
      " Hello World\n",
      " Hello World\n",
      " Hello World\n"
     ]
    }
   ],
   "source": [
    "!!%compiler: gfortran\n",
    "!!%cflags: -fopenmp\n",
    "\n",
    "PROGRAM Parallel_Hello_World\n",
    "USE OMP_LIB\n",
    "\n",
    "!$OMP PARALLEL\n",
    "\n",
    "  PRINT *, \"Hello World\"\n",
    "\n",
    "!$OMP END PARALLEL\n",
    "\n",
    "END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5c99192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Hello World\n",
      " Hello World\n",
      " Hello World\n",
      " Hello World\n"
     ]
    }
   ],
   "source": [
    "!!%compiler: gfortran\n",
    "!!%cflags: -fopenmp\n",
    "\n",
    "PROGRAM Parallel_Hello_World\n",
    "USE OMP_LIB\n",
    "\n",
    "!$OMP PARALLEL num_threads(4)\n",
    "\n",
    "  PRINT *, \"Hello World\"\n",
    "\n",
    "!$OMP END PARALLEL\n",
    "\n",
    "END"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a00d26",
   "metadata": {},
   "source": [
    "The syntax of **parallel** directive in Fortran is:\n",
    "```\n",
    "!$omp parallel do [clause[ [,] clause] ... ]\n",
    "    loop-nest\n",
    "[!$omp end parallel do]\n",
    "```\n",
    "\n",
    "Within a parallel region, the thread number uniquely identifies each thread. A thread can obtain its own thread number by calling the **omp_get_thread_num** library routine.\n",
    "\n",
    "The following example is a little more complicated. It shows how to use the **omp_get_thread_num** library routine, and shows how to use two other clauses, the **default** clause and the **private** clause. It assigns tasks to each thread explicitly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "229651ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "123.456001 123.456001 123.456001 123.456001 123.456001 \n",
      "123.456001 123.456001 123.456001 123.456001 123.456001 \n",
      "123.456001 123.456001 123.456001 123.456001 123.456001 \n",
      "123.456001 123.456001 123.456001 123.456001 123.456001 \n",
      "123.456001 123.456001 123.456001 123.456001 123.456001 \n",
      "123.456001 123.456001 123.456001 123.456001 123.456001 \n",
      "123.456001 123.456001 123.456001 123.456001 123.456001 \n",
      "123.456001 123.456001 123.456001 123.456001 123.456001 \n",
      "123.456001 123.456001 123.456001 123.456001 123.456001 \n",
      "123.456001 123.456001 123.456001 123.456001 123.456001 "
     ]
    }
   ],
   "source": [
    "//%compiler: clang\n",
    "//%cflags: -fopenmp\n",
    "\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <omp.h>\n",
    "\n",
    "void subdomain(float *x, int istart, int ipoints) {\n",
    "    int i;\n",
    "    for (i = 0; i < ipoints; i++)       \n",
    "         x[istart+i] = 123.456;\n",
    "}\n",
    "\n",
    "void sub(float *x, int npoints) {\n",
    "    int iam, nt, ipoints, istart;\n",
    "    #pragma omp parallel default(shared) private(iam,nt,ipoints,istart)\n",
    "    {\n",
    "        iam = omp_get_thread_num();\n",
    "        nt = omp_get_num_threads();\n",
    "        ipoints = npoints / nt; /* size of partition */\n",
    "        istart = iam * ipoints; /* starting array index */\n",
    "        if (iam == nt-1) /* last thread may do more */\n",
    "            ipoints = npoints - istart;\n",
    "        subdomain(x, istart, ipoints);\n",
    "    }\n",
    "}\n",
    "\n",
    "void print(float *x, int npoints) {\n",
    "    for (int i = 0; i < npoints; i++) {\n",
    "        if(i++ % 10 == 0)\n",
    "            printf(\"\\n\");\n",
    "        printf(\"%f \", x[i]);\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    float array[100];\n",
    "    sub(array, 100);\n",
    "    print(array, 100);\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6a9f51",
   "metadata": {},
   "source": [
    "In the above example, we use the default number of threads to perform assignment operations on 100 elements in the array. Tasks are evenly distributed to each thread, and when the number of tasks is not divisible by the number of threads, the remaining tasks will be completed by the last thread.\n",
    "\n",
    "When programming in parallel, the most important and hardest part is how to assign tasks and manage threads. We already introduced that a thread can get its own id through the **omp_get_thread_num** routine. Another important routine is **omp_get_num_threads**, which returns the number of threads in the current team.\n",
    "\n",
    "In the above example, variable *npoints* presents the total number of elements in the array, and it is divided into *nt* parts, each of size *ipoints*. The starting address of each part is *istart*. Each part is completed by one thread, and a total of 8 threads execute tasks in parallel.\n",
    "\n",
    "The **default** clause is used to define the default data-sharing attributes of variables that are referenced in a parallel, teams, or task generating construct. In the above example, *default(shared)* indicates that by default, the variables in the parallel region are shared variables.\n",
    "The **private** clause is used to explicitly specify variables that are private in each task or SIMD lane (SIMD will be introduced in the next chapter). In the above example, the variables *iam, nt, ipoints* and *istart* are private variables for each thread, which means a thread cannot access these variables of another thread.\n",
    "\n",
    "Both of these two clauses belong to the data-sharing attribute clauses, which we will introduce in detail in the section of clauses later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24ad80a",
   "metadata": {},
   "source": [
    "### **teams** Directive\n",
    "The **teams** directive indicates that the loop that follows is split among multiple thread teams, one thread team computing one part of the task. Developers can use the **teams** directive to use a large number of thread teams.\n",
    "\n",
    "The following figure shows the execution model of the **teams** directive:\n",
    "![teams_directive](teams.jpeg \"topic1\")\n",
    "\n",
    "A league of teams is created when a thread encounters a **teams** construct. Each team is an initial team, and the initial thread in each team executes the team area.\n",
    "After a team is created, the number of initial teams remains the same for the duration of the **teams** region.\n",
    "Within a **teams** region, the initial team number uniquely identifies each initial team. A thread can obtain its own initial team number by calling the *omp_get_team_num* library routine.\n",
    "The teams directive has the following characteristics:\n",
    "- the **teams** directive can spawn one or more thread teams with the same number of threads\n",
    "- code is portable for one thread team or multiple thread teams\n",
    "- only the primary thread of each team continues to execute\n",
    "- no synchronization between thread teams\n",
    "- programmers don't need to think about how to decompose loops\n",
    "\n",
    "OpenMP was originally designed for multithreading on shared-memory parallel computers, so the parallel directive only creates a single layer of parallelism.\n",
    "The team instruction is used to express the second level of scalable parallelization. Before OpenMP 5.0, it can be only used on the GPU (with an associated target construct). In OpenMP 5.0 the **teams** construct was extended to enable the host to execute a teams region.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c62d988b-cd16-4ba2-9c6d-1bfe43666a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "clang: error: cannot find libdevice for sm_35. Provide path to different CUDA installation via --cuda-path, or pass -nocudalib to build without linking with libdevice.\n",
      "[Native kernel] clang exited with code 1, the executable will not be executed"
     ]
    }
   ],
   "source": [
    "//%compiler: clang\n",
    "//%cflags: -fopenmp -fopenmp-targets=nvptx64-nvidia-cuda  --cuda-path=/usr/local/cuda\n",
    "#include <stdlib.h>\n",
    "#include <omp.h>\n",
    "float dotprod(float B[], float C[], int N) {\n",
    "    float sum0 = 0.0;\n",
    "    float sum1 = 0.0;\n",
    "    #pragma omp target map(to: B[:N], C[:N]) map(tofrom: sum0, sum1)\n",
    "    #pragma omp teams num_teams(2) \n",
    "    {\n",
    "        int i;\n",
    "        if (omp_get_num_teams() != 2)\n",
    "            abort();\n",
    "        if (omp_get_team_num() == 0) {\n",
    "            #pragma omp parallel for reduction(+:sum0)\n",
    "            for (i=0; i<N/2; i++)\n",
    "                sum0 += B[i] * C[i];\n",
    "        } else if (omp_get_team_num() == 1) {\n",
    "            #pragma omp parallel for reduction(+:sum1)\n",
    "            for (i=N/2; i<N; i++)\n",
    "                sum1 += B[i] * C[i];\n",
    "        }\n",
    "    }\n",
    "    return sum0 + sum1;\n",
    "}\n",
    "/* Note: The variables sum0,sum1 are now mapped with tofrom, for correct\n",
    " execution with 4.5 (and pre-4.5) compliant compilers. See Devices Intro.\n",
    " */"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8a758b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/tmpwit3re_h.c:16:5: error: orphaned 'omp teams' directives are prohibited; perhaps you forget to enclose the directive into a target region?\n",
      "    #pragma omp teams num_teams(nteams_required) thread_limit(max_thrds) private(tm_id)\n",
      "    ^\n",
      "1 error generated.\n",
      "[Native kernel] clang exited with code 1, the executable will not be executed"
     ]
    }
   ],
   "source": [
    "//%compiler: clang\n",
    "//%cflags: -fopenmp\n",
    "\n",
    "// Need to update the native kernel, or specified that our kernel doesn't support OpenMP 5.0\n",
    "\n",
    "\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <math.h>\n",
    "#include <omp.h>\n",
    "#define N 1000\n",
    " \n",
    "int main(){\n",
    "    int nteams_required=2, max_thrds, tm_id;\n",
    "    float sp_x[N], sp_y[N], sp_a=0.0001e0;\n",
    "    double dp_x[N], dp_y[N], dp_a=0.0001e0;\n",
    "\n",
    "    // Create 2 teams, each team works in a different precision\n",
    "    #pragma omp teams num_teams(nteams_required) thread_limit(max_thrds) private(tm_id)\n",
    "    {\n",
    "        tm_id = omp_get_team_num();\n",
    "        if( omp_get_num_teams() != 2 ) //if only getting 1, quit \n",
    "        { \n",
    "            printf(\"error: Insufficient teams on host, 2 required\\n\");\n",
    "            exit(0);\n",
    "        }\n",
    "        if(tm_id == 0) // Do Single Precision Work (SAXPY) with this team\n",
    "        {\n",
    "            #pragma omp parallel\n",
    "            {\n",
    "                #pragma omp for //init\n",
    "                for(int i=0; i<N; i++){sp_x[i] = i*0.0001; sp_y[i]=i; }\n",
    "                #pragma omp for simd simdlen(8)\n",
    "                for(int i=0; i<N; i++){sp_x[i] = sp_a*sp_x[i] + sp_y[i];}\n",
    "            }\n",
    "        }\n",
    "        if(tm_id == 1) // Do Double Precision Work (DAXPY) with this team\n",
    "        {\n",
    "            #pragma omp parallel\n",
    "            {\n",
    "                #pragma omp for //init\n",
    "                for(int i=0; i<N; i++){dp_x[i] = i*0.0001; dp_y[i]=i; }\n",
    "                #pragma omp for simd simdlen(4)\n",
    "                for(int i=0; i<N; i++){dp_x[i] = dp_a*dp_x[i] + dp_y[i];}\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    printf(\"i=%d sp|dp %f %f \\n\",N-1, sp_x[N-1], dp_x[N-1]);\n",
    "    printf(\"i=%d sp|dp %f %f \\n\",N/2, sp_x[N/2], dp_x[N/2]);\n",
    "    //OUTPUT1:i=999 sp|dp 999.000000 999.000010\n",
    "    //OUTPUT2:i=500 sp|dp 500.000000 500.000005\n",
    "    return 0;\n",
    "} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3337ed06",
   "metadata": {},
   "source": [
    "Its syntax is:\n",
    "```\n",
    "#pragma omp teams [clause[ [,] clause] ... ] new-line\n",
    "    structured-block\n",
    "```\n",
    "The syntax in Fortran is:\n",
    "```\n",
    "!$omp teams [clause[ [,] clause] ... ]\n",
    "    loosely-structured-block\n",
    "!$omp end teams\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909431d7",
   "metadata": {},
   "source": [
    "## Clauses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b3c821",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "996c6982",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b8fef41a",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Native",
   "language": "native",
   "name": "native"
  },
  "language_info": {
   "file_extension": ".c",
   "mimetype": "text/plain",
   "name": "c"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
